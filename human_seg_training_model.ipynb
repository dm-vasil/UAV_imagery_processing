{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_extraction import image as skimg\n",
    "from skimage.util import view_as_windows\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import xmltodict\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, Activation, Cropping2D, ZeroPadding2D, Concatenate\n",
    "from keras.layers import concatenate, BatchNormalization, Dropout, Lambda\n",
    "from keras.applications import ResNet50, VGG16, VGG19\n",
    "from keras import backend as K\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import segmentation_models as sm\n",
    "import csv\n",
    "import pandas as pd\n",
    "#import xmltodict\n",
    "\n",
    "import gc\n",
    "#from torch.nn.utils import spectral_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constatns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_dataset_folder = r'.\\Datasets\\dataset_human_white\\LABELED\\LABELED\\images\\classified_humans'\n",
    "human_labels_folder = r'.\\Datasets\\dataset_human_white\\LABELED\\LABELED\\labels\\classified_humans'\n",
    "\n",
    "dataset_4k_folder = r'.\\Datasets\\drone_dataset_human_4k\\ntut_drone_train\\ntut_drone_train\\Drone_005\\vott-csv-export'\n",
    "csv_folder = r'.\\Datasets\\drone_dataset_human_4k\\labels'\n",
    "\n",
    "snow_dataset_folder = r'.\\Datasets\\other_human_archive\\images\\train'\n",
    "snow_xml_folder = r'.\\Datasets\\other_human_archive\\XML_annotations'\n",
    "\n",
    "minmaxscaler = MinMaxScaler()\n",
    "IMG_SIZE = (512, 512) #(1024,1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing images and mask files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing LaDD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "1064\n",
      "1064\n"
     ]
    }
   ],
   "source": [
    "#LaDD dataset\n",
    "\n",
    "# Define the constants\n",
    "image_dataset = []\n",
    "mask_dataset = []\n",
    "images_fold = snow_dataset_folder\n",
    "labels_fold = snow_xml_folder\n",
    "scale = 2\n",
    "\n",
    "df = pd.read_csv(csv_folder+\"\\Drone_005-export.csv\")\n",
    "\n",
    "def preprocess_mask(img_shape, directory, filename):\n",
    "    label_file = os.path.join(directory, filename.replace('.jpg','.xml'))\n",
    "    image_size = (img_shape[0], img_shape[1])\n",
    "    mask_image = np.zeros(image_size, dtype=np.uint8)\n",
    "    if os.path.isfile(label_file):\n",
    "        with open(label_file, \"r\") as f:\n",
    "            xml_content = f.read()\n",
    "            # Convert the XML string to a dictionary\n",
    "            xml_dict = xmltodict.parse(xml_content)\n",
    "            if (isinstance(xml_dict[\"annotation\"][\"object\"], list)):\n",
    "                for i in range(len(xml_dict[\"annotation\"][\"object\"])):\n",
    "                    x = np.float32(xml_dict[\"annotation\"][\"object\"][i][\"bndbox\"][\"xmin\"])\n",
    "                    y = np.float32(xml_dict[\"annotation\"][\"object\"][i][\"bndbox\"][\"ymin\"])\n",
    "                    width = np.float32(xml_dict[\"annotation\"][\"object\"][i][\"bndbox\"][\"xmax\"])\n",
    "                    height = np.float32(xml_dict[\"annotation\"][\"object\"][i][\"bndbox\"][\"ymax\"])\n",
    "                    x1 = int(x//scale)\n",
    "                    y1 = int(y//scale)\n",
    "                    x2 = int(width//scale)\n",
    "                    y2 = int(height//scale)\n",
    "                    cv2.rectangle(mask_image, (x1, y1), (x2, y2), color=255, thickness=-1)\n",
    "            else:\n",
    "                x = np.float32(xml_dict[\"annotation\"][\"object\"][\"bndbox\"][\"xmin\"])\n",
    "                y = np.float32(xml_dict[\"annotation\"][\"object\"][\"bndbox\"][\"ymin\"])\n",
    "                width = np.float32(xml_dict[\"annotation\"][\"object\"][\"bndbox\"][\"xmax\"])\n",
    "                height = np.float32(xml_dict[\"annotation\"][\"object\"][\"bndbox\"][\"ymax\"])\n",
    "                x1 = int(x//scale)\n",
    "                y1 = int(y//scale)\n",
    "                x2 = int(width//scale)\n",
    "                y2 = int(height//scale)\n",
    "                cv2.rectangle(mask_image, (x1, y1), (x2, y2), color=255, thickness=-1)\n",
    "    mask_image = cv2.cvtColor(mask_image, cv2.COLOR_BGR2RGB)\n",
    "    return mask_image\n",
    "\n",
    "for filename in os.listdir(images_fold):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_file = os.path.join(images_fold, filename)\n",
    "        image = cv2.imread(image_file)\n",
    "        image = cv2.resize(image, [image.shape[1]//scale,image.shape[0]//scale])\n",
    "        if image is not None:\n",
    "            images = [cv2.cvtColor(image, cv2.COLOR_BGR2RGB), preprocess_mask(image.shape, labels_fold, filename)]\n",
    "            for ind in range(2):\n",
    "                size_x = (images[ind].shape[1] // IMG_SIZE) * IMG_SIZE\n",
    "                size_y = (images[ind].shape[0] // IMG_SIZE) * IMG_SIZE\n",
    "                patched_images = view_as_windows(images[ind].astype(np.float32), (IMG_SIZE, IMG_SIZE, 3), step=IMG_SIZE)\n",
    "                patched_images = patched_images.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "                for patch in patched_images:\n",
    "                    patch = minmaxscaler.fit_transform(patch.reshape(-1, patch.shape[-1])).reshape(patch.shape)\n",
    "                    if ind is 0:\n",
    "                        image_dataset.append(patch)\n",
    "                    else:\n",
    "                        mask_dataset.append(patch)\n",
    "print(i)\n",
    "print(len(image_dataset))\n",
    "print(len(mask_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing dataset Human in white clothes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "4164\n",
      "4164\n"
     ]
    }
   ],
   "source": [
    "#White human dataset\n",
    "# Define the constants\n",
    "image_types = {\"images\": \"jpg\", \"masks\": \"txt\"} # The image types and extensions\n",
    "image_dataset = []\n",
    "mask_dataset = []\n",
    "images_fold = human_dataset_folder\n",
    "labels_fold = human_labels_folder\n",
    "\n",
    "def preprocess_mask(img_shape, directory, filename):\n",
    "    label_file = os.path.join(directory, filename.replace('.jpg','.txt'))\n",
    "    image_size = (img_shape[0], img_shape[1])\n",
    "    mask_image = np.zeros(image_size, dtype=np.uint8)\n",
    "    if os.path.isfile(label_file):\n",
    "        with open(label_file, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        for line in lines:\n",
    "            class_id, x, y, width, height = map(float, line.split())\n",
    "            x1 = int((x - width / 2) * image_size[1])\n",
    "            y1 = int((y - height / 2) * image_size[0])\n",
    "            x2 = int((x + width / 2) * image_size[1])\n",
    "            y2 = int((y + height / 2) * image_size[0])\n",
    "            cv2.rectangle(mask_image, (x1, y1), (x2, y2), color=255, thickness=-1)\n",
    "    mask_image = cv2.cvtColor(mask_image, cv2.COLOR_BGR2RGB)\n",
    "    return mask_image\n",
    "\n",
    "for filename in os.listdir(images_fold):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_file = os.path.join(images_fold, filename)\n",
    "        image = cv2.imread(image_file)\n",
    "        if image is not None:\n",
    "            images = [cv2.cvtColor(image, cv2.COLOR_BGR2RGB), preprocess_mask(image.shape, labels_fold, filename.replace('.jpg','.txt'))]\n",
    "            for ind in range(2):\n",
    "                size_x = (images[ind].shape[1] // IMG_SIZE) * IMG_SIZE\n",
    "                size_y = (images[ind].shape[0] // IMG_SIZE) * IMG_SIZE\n",
    "                patched_images = view_as_windows(images[ind].astype(np.float32), (IMG_SIZE, IMG_SIZE, 3), step=IMG_SIZE)\n",
    "                patched_images = patched_images.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "                for patch in patched_images:\n",
    "                    patch = minmaxscaler.fit_transform(patch.reshape(-1, patch.shape[-1])).reshape(patch.shape)\n",
    "                    if ind is 0:\n",
    "                        image_dataset.append(patch)\n",
    "                    else:\n",
    "                        mask_dataset.append(patch)\n",
    "print(i)\n",
    "print(len(image_dataset))\n",
    "print(len(mask_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing dataset 4k human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4k dataset\n",
    "\n",
    "# Define the constants\n",
    "image_dataset = []\n",
    "mask_dataset = []\n",
    "images_fold = dataset_4k_folder\n",
    "labels_fold = csv_folder\n",
    "scale = 4\n",
    "\n",
    "df = pd.read_csv(csv_folder+\"\\Drone_005-export.csv\")\n",
    "\n",
    "def preprocess_mask(img_shape, filename):\n",
    "    label_lines = df[df['image']==filename]\n",
    "    image_size = (img_shape[0], img_shape[1])\n",
    "    mask_image = np.zeros(image_size, dtype=np.uint8)\n",
    "    if label_lines.empty is not True: \n",
    "            for index, row in label_lines.iterrows():\n",
    "                x, y, width, height,  = map(float, row[1:5])\n",
    "                x1 = int(x//scale)\n",
    "                y1 = int(y//scale)\n",
    "                x2 = int(width//scale)\n",
    "                y2 = int(height//scale)\n",
    "                cv2.rectangle(mask_image, (x1, y1), (x2, y2), color=255, thickness=-1)\n",
    "    mask_image = cv2.cvtColor(mask_image, cv2.COLOR_BGR2RGB)\n",
    "    return mask_image\n",
    "\n",
    "for filename in os.listdir(images_fold):\n",
    "    #print(filename)\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_file = os.path.join(images_fold, filename)\n",
    "        image = cv2.imread(image_file)\n",
    "        image = cv2.resize(image, [image.shape[1]//scale,image.shape[0]//scale])\n",
    "        #print(image.shape)\n",
    "        if image is not None:\n",
    "            images = [cv2.cvtColor(image, cv2.COLOR_BGR2RGB), preprocess_mask(image.shape, filename.replace('.jpg',''))]\n",
    "            for ind in range(2):\n",
    "                size_x = (images[ind].shape[1] // IMG_SIZE) * IMG_SIZE\n",
    "                size_y = (images[ind].shape[0] // IMG_SIZE) * IMG_SIZE\n",
    "                patched_images = view_as_windows(images[ind].astype(np.float32), (IMG_SIZE, IMG_SIZE, 3), step=IMG_SIZE)\n",
    "                patched_images = patched_images.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "                for patch in patched_images:\n",
    "                    patch = minmaxscaler.fit_transform(patch.reshape(-1, patch.shape[-1])).reshape(patch.shape)\n",
    "                    if ind is 0:\n",
    "                        image_dataset.append(patch)\n",
    "                    else:\n",
    "                        mask_dataset.append(patch)\n",
    "print(i)\n",
    "print(len(image_dataset))\n",
    "print(len(mask_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making classes based on mask colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255]\n",
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "class_human = np.array(tuple([255,255,255]))\n",
    "print(class_human)\n",
    "\n",
    "class_unlabeled = np.array(tuple([0,0,0]))\n",
    "print(class_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_label(label):\n",
    "  label_segment = np.zeros(label.shape, dtype=np.uint8)\n",
    "  label_segment[np.all(label == class_human, axis=-1)] = 0\n",
    "  label_segment[np.all(np.uint8(label*255) == class_unlabeled, axis=-1)] = 1\n",
    "  #label_segment[np.all(np.uint8(label*255) == class_test, axis=-1)] = 2\n",
    "  label_segment = label_segment[:,:,0]\n",
    "  return label_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(mask_dataset.shape[0]):\n",
    "  label = rgb_to_label(mask_dataset[i])\n",
    "  labels.append(label)\n",
    "labels = np.array(labels)\n",
    "labels = np.expand_dims(labels, axis=3)\n",
    "total_classes = len(np.unique(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_trianing_dataset = image_dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(master_trianing_dataset, labels_categorical_dataset, test_size=0.15, random_state=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_conv_block(inputs, filters, activation='relu', batch_norm=True, groups=32):\n",
    "    channel_axis = -1\n",
    "    input_channels = inputs.shape[channel_axis]\n",
    "    group_size = input_channels // groups\n",
    "    group_list = []\n",
    "\n",
    "    for i in range(groups):\n",
    "        group = inputs[:, :, :, i * group_size:(i + 1) * group_size]\n",
    "        group = Conv2D(filters // groups, (3, 3), padding='same')(group)\n",
    "        if batch_norm:\n",
    "            group = BatchNormalization()(group)\n",
    "        group = Activation(activation)(group)\n",
    "        group_list.append(group)\n",
    "\n",
    "    x = Concatenate(axis=channel_axis)(group_list)\n",
    "    return x\n",
    "\n",
    "def custom_residual_block(inputs, filters):\n",
    "    x = group_conv_block(inputs, filters)\n",
    "    x = group_conv_block(x, filters)\n",
    "    shortcut = Conv2D(filters, (1, 1), padding='same')(inputs)\n",
    "    x = Add()([x, shortcut])\n",
    "    return x\n",
    "\n",
    "def unet(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    resnet = ResNet50(include_top=False, weights='imagenet', input_tensor=inputs)\n",
    "    encoder_layers = [resnet.get_layer(layer_name).output for layer_name in ['conv1_relu', 'conv2_block3_out', 'conv3_block4_out', 'conv4_block6_out']]\n",
    "    \n",
    "    x = resnet.get_layer('conv5_block3_out').output\n",
    "    x = custom_residual_block(x, 2048)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    filters = 1024\n",
    "    for i in range(4):\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Concatenate()([x, encoder_layers[-(i+1)]])\n",
    "        x = custom_residual_block(x, filters)\n",
    "        x = Dropout(0.5)(x)\n",
    "        filters //= 2\n",
    "\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "\n",
    "input_shape = (256, 256, 3)\n",
    "n_classes = total_classes\n",
    "model = unet(input_shape, n_classes)\n",
    "\n",
    "# Fine-tune the pre-trained ResNet50 layers\n",
    "for layer in model.layers[:len(model.layers) - 1]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_coef(y_true, y_pred):\n",
    "  y_true_flatten = K.flatten(y_true)\n",
    "  y_pred_flatten = K.flatten(y_pred)\n",
    "  intersection = K.sum(y_true_flatten * y_pred_flatten)\n",
    "  final_coef_value = (intersection + 1.0) / (K.sum(y_true_flatten) + K.sum(y_pred_flatten) - intersection + 1.0)\n",
    "  return final_coef_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.5, 0.5]\n",
    "dice_loss = sm.losses.DiceLoss(class_weights = weights)\n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers, callbacks\n",
    "metrics = [\"accuracy\", jaccard_coef]\n",
    "EPOCHS = 120\n",
    "LR = 0.0002\n",
    "optim = optimizers.Adam(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optim, loss=total_loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining callbacks, saving best model and reducing learning rate while training stuck on the same loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    callbacks.ModelCheckpoint('./best_model_ternaus.h5', save_weights_only=True, save_best_only=True, mode='min'),\n",
    "    callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=3, min_lr=1e-9, verbose=1),\n",
    "]\n",
    "model.optimizer.lr.assign(2e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if training on gpu is available and prevent memory from overflowing after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU')) \n",
    "\n",
    "# Check if a GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    print('GPU is not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualazing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file=\"satellite_model_plot3.png\", show_shapes=True, show_layer_names=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "!wandb login \"hidden, due to github publicity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"human_segmentation_lame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(X_train, y_train,\n",
    "                          batch_size=4,\n",
    "                          verbose=1,\n",
    "                          epochs=120,\n",
    "                          validation_data=(X_test, y_test),\n",
    "                          callbacks = [callbacks, WandbCallback()],\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_a = model_history\n",
    "history_a.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history_a.history['loss']\n",
    "val_loss = history_a.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label=\"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'r', label=\"Validation Loss\")\n",
    "plt.title(\"Training Vs Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_coef = history_a.history['iou_score']\n",
    "val_jaccard_coef = history_a.history['val_iou_score']\n",
    "\n",
    "epochs = range(1, len(jaccard_coef) + 1)\n",
    "plt.plot(epochs, jaccard_coef, 'y', label=\"Training IoU\")\n",
    "plt.plot(epochs, val_jaccard_coef, 'r', label=\"Validation IoU\")\n",
    "plt.title(\"Training Vs Validation IoU\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
