{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import re\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Dropout, Input, add, Conv2D, BatchNormalization, MaxPooling2D, Conv2DTranspose,Activation, Concatenate\n",
    "from tensorflow import keras\n",
    "from time import time\n",
    "from keras import backend as K\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "import segmentation_models as sm\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# import keras_retinanet\n",
    "from lacmus.keras_retinanet import models\n",
    "from lacmus.keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from lacmus.keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from lacmus.keras_retinanet.utils.colors import label_color\n",
    "\n",
    "import networkx as nx\n",
    "from itertools import product\n",
    "from shortestpaths import k_shortest_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constatns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (512, 512) #(1024,1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0) \n",
    " \n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    dice_loss = dice_coef_loss(y_true, y_pred)\n",
    "    bce_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    return 0.5 * bce_loss + 0.5 * dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def placeMaskOnImg(img, mask, color):\n",
    "    color = [i/255.0 for i in color]\n",
    "    np.place(img[:, :, :], mask[:, :, :] >= 0.5, color)\n",
    "    return img\n",
    "\n",
    "def make_pred_good(pred):\n",
    "#     pred = pred.numpy()\n",
    "    pred = pred[0][:, :, :]\n",
    "    pred = np.repeat(pred, 3, 2)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Road model load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'resnet50'\n",
    "n_classes = 1\n",
    "activation = 'sigmoid'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "road_model = sm.Unet(BACKBONE, classes=n_classes, activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_weights_path =  'road_model__120epochs.h5'\n",
    "road_model.load_weights(road_weights_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "human_model_path = 'human_model_120epochs.h5'\n",
    "human_model = models.load_model(human_model_path, backbone_name='resnet50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coords to pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixels_by_coords(t_lat,t_lon, rb_lat, rb_lon):\n",
    "    b_lat, b_lon = 56.4, 37.93937397222222\n",
    "    lat, lon = 56.3935451, 37.9920535\n",
    "    h, w = 86//2, 386//2\n",
    "    lat_coeff = h/(b_lat-lat)\n",
    "    lon_coeff = w/(b_lon-lon)\n",
    "\n",
    "    pix_h, pix_w = int((rb_lat-t_lat)*lat_coeff), int((rb_lon-t_lon)*lon_coeff)\n",
    "\n",
    "    return pix_h, pix_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating graph out of the mask and finding three shortest parts to nearest localties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "def create_graph(matrix, threshold=10):\n",
    "    rows, cols = matrix.shape\n",
    "    graph = nx.DiGraph()\n",
    "\n",
    "    for i, j in product(range(rows), range(cols)):\n",
    "        if matrix[i, j] == 1:\n",
    "            graph.add_node((i, j))\n",
    "\n",
    "            for x, y in product(range(i - threshold, i + threshold + 1), range(j - threshold, j + threshold + 1)):\n",
    "                if 0 <= x < rows and 0 <= y < cols and matrix[x, y] == 1 and ((x - i) ** 2 + (y - j) ** 2) <= threshold ** 2:\n",
    "                    graph.add_edge((i, j), (x, y), weight=((x - i) ** 2 + (y - j) ** 2) ** 0.5)\n",
    "\n",
    "    return graph\n",
    "\n",
    "def find_three_shortest_paths(matrix, start, end, threshold=10):\n",
    "    graph = create_graph(matrix, threshold)\n",
    "    paths = list(k_shortest_paths(graph, start, end, 1, 'd'))#, weight='weight'\n",
    "    return paths#result_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing coordinates from UAV aerial photo and getting sattelite map from this coordinates, also decorating this map with labels and markdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from exif import Image\n",
    "import json\n",
    "import folium\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import great_circle\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import time\n",
    "\n",
    "def decimal_coords(coords, ref): # Convert GPS to degrees\n",
    "    decimal_degrees = coords[0] + coords[1] / 60 + coords[2] / 3600\n",
    "    if ref == \"S\" or ref == \"W\":\n",
    "        decimal_degrees = -decimal_degrees\n",
    "    return decimal_degrees\n",
    "\n",
    "def image_coordinates(image_path): # Get GPS\n",
    "    with open(image_path, \"rb\") as src:\n",
    "        img = Image(src)\n",
    "        if img.has_exif:\n",
    "            try:\n",
    "                lat = decimal_coords(img.gps_latitude, img.gps_latitude_ref)\n",
    "                lon = decimal_coords(img.gps_longitude, img.gps_longitude_ref)\n",
    "                return (lat, lon)\n",
    "            except AttributeError:\n",
    "                print(\"No coordinates\")\n",
    "        else:\n",
    "            print(\"The image has no EXIF information\")\n",
    "\n",
    "#getting map by coords and marking recognized humans on the map\n",
    "def place_human_labels(amount):\n",
    "    driver = webdriver.Firefox() \n",
    "    driver.get(\"file://\" + os.path.abspath(\"map.html\"))\n",
    "    time.sleep(1)\n",
    "    map_path = \"map.png\"\n",
    "    driver.save_screenshot(map_path)\n",
    "    driver.quit()\n",
    "    mask_m = plt.imread(map_path)\n",
    "    plt.imsave(fname=map_path[:-3]+'jpg',arr = mask_m)\n",
    "    del mask_m\n",
    "    # remove the png file, but keep the 8-bit mask\n",
    "    os.remove(map_path)\n",
    "    satellite_map = plt.imread(\"map.jpg\")\n",
    "    base_h, base_w = satellite_map.shape[0]//2, satellite_map.shape[1]//2\n",
    "    img = cv2.rectangle(satellite_map, (base_w-20, base_h-20, 40, 40),(255,0,0),2)\n",
    "\n",
    "    img = cv2.putText(satellite_map, str(amount), (base_w-10, base_h+10), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 0), 2)\n",
    "    return satellite_map\n",
    "\n",
    "#getting nearest localties and marking them\n",
    "def get_map(image_source, amount):\n",
    "    api_key = \"hidden\"\n",
    "    latitude, longitude = 56.07461313,34.43509312 #basic coords for my screen resolution\n",
    "    location = f'{latitude}, {longitude}'\n",
    "    radius = 6000\n",
    "    zoom = 14\n",
    "    type = \"city|village\"\n",
    "    url = f\"https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={location}&radius={radius}&type={type}&key={api_key}\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    results = response.json()[\"results\"]\n",
    "\n",
    "    print(f\"Found {len(results)} nearby cities and villages.\")\n",
    "\n",
    "    places = []\n",
    "\n",
    "    for result in results:\n",
    "    \n",
    "        place_id = result[\"place_id\"]\n",
    "        \n",
    "        fields = \"name,formatted_address,geometry\"\n",
    "        url = f\"https://maps.googleapis.com/maps/api/place/details/json?place_id={place_id}&fields={fields}&key={api_key}\"\n",
    "\n",
    "        response = requests.get(url)\n",
    "        result = response.json()[\"result\"]\n",
    "\n",
    "    \n",
    "        place = {\n",
    "            \"name\": result[\"name\"],\n",
    "            \"address\": result[\"formatted_address\"],\n",
    "            \"lat\": result[\"geometry\"][\"location\"][\"lat\"],\n",
    "            \"lng\": result[\"geometry\"][\"location\"][\"lng\"]\n",
    "        }\n",
    "\n",
    "        places.append(place)\n",
    "        \n",
    "    geolocator = Nominatim(user_agent=\"myGeocoder\")\n",
    "\n",
    "\n",
    "    m = folium.Map(location=[latitude, longitude], zoom_start=13, tiles=\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\", attr=\"Esri\")\n",
    "    m_unlabelled = folium.Map(location=[latitude, longitude], zoom_start=13, tiles=\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\", attr=\"Esri\")\n",
    "    folium.Marker([latitude, longitude], popup=\"Your Location\", icon=folium.Icon(color=\"blue\")).add_to(m)\n",
    "    \n",
    "    \n",
    "    for place in places:\n",
    "        \n",
    "        print(place)\n",
    "        nearest_lat, nearest_lon = place[\"lat\"], place[\"lng\"]\n",
    "        folium.Marker([nearest_lat, nearest_lon], popup=\"Nearest Settlement\", icon=folium.Icon(color=\"red\")).add_to(m)\n",
    "\n",
    "    m.save(\"map.html\")\n",
    "    m_unlabelled.save(\"map_unlabelled.html\")\n",
    "    driver = webdriver.Firefox() \n",
    "    driver.get(\"file://\" + os.path.abspath(\"map_unlabelled.html\"))\n",
    "    time.sleep(1)\n",
    "    map_path = \"map_unlabelled.png\"\n",
    "    driver.save_screenshot(map_path)\n",
    "    driver.quit()\n",
    "    mask_m = plt.imread(map_path)\n",
    "    plt.imsave(fname=map_path[:-3]+'jpg',arr = mask_m)\n",
    "    del mask_m\n",
    "    # remove the png file, but keep the 8-bit mask\n",
    "    os.remove(map_path)\n",
    "    labelled_map = place_human_labels(amount)\n",
    "    satellite_map = plt.imread(\"map_unlabelled.jpg\")\n",
    "    return labelled_map, satellite_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding, which part of recognized roads is closest to the recognized humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(matrix, start_coord):\n",
    "    mask = np.ma.masked_not_equal(matrix, 1)\n",
    "    indices = np.argwhere(mask.mask == False)\n",
    "    distances = [np.sqrt((i[0]-start_coord[0])**2 + (i[1]-start_coord[1])**2) for i in indices]\n",
    "    closest_index = distances.index(min(distances))\n",
    "    return tuple(indices[closest_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making input picture smoother for better recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_image(image):\n",
    "    pixels = np.array(image)\n",
    "    reshaped_pixels = pixels.reshape((-1, 3))\n",
    "    n_clusters = 8\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=1).fit(reshaped_pixels)\n",
    "    new_pixels = kmeans.cluster_centers_[kmeans.labels_].astype(np.uint8)\n",
    "    new_image =  new_pixels.reshape(pixels.shape)  #Image.fromarray(new_pixels.reshape(pixels.shape))\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mitty\\anaconda3\\envs\\ml\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting map with right human labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_satellite_map_from_image(image_source, amount):\n",
    "        amount = int(amount['label'].split()[0])\n",
    "        img = get_map(image_source, amount)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating borders for better patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_borders_UI(img, desired_size=IMG_SIZE):\n",
    "    delta_w = (img.shape[0] if img.shape[0]%desired_size[0]==0 else ((img.shape[0]//desired_size[0])+1)*desired_size[0]) - img.shape[0]\n",
    "    delta_h = (img.shape[1] if img.shape[1]%desired_size[1]==0 else ((img.shape[1]//desired_size[1])+1)*desired_size[1]) - img.shape[1]\n",
    "    img = cv2.copyMakeBorder(img, 0, delta_w, 0, delta_h, cv2.BORDER_CONSTANT, value=1)\n",
    "    return img "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing staellite map image to recognize roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_road_image(image_source, patch_size=(800,800)):\n",
    "    img = interpolate_image(image_source)\n",
    "    img = (image_source/255.0).astype(np.float32)\n",
    "    img = np.expand_dims(cv2.resize(img, (512, 512)), 0)\n",
    "    \n",
    "    predicted_images = []\n",
    "    img_patches = []\n",
    "    \n",
    "    for y in range(0, img.shape[0], patch_size[1]):\n",
    "        for x in range(0, img.shape[1], patch_size[0]):\n",
    "            img_patch = img[y:y + patch_size[1], x:x + patch_size[0]]\n",
    "            img_patches.append(cv2.resize(img_patch, (512, 512)))     \n",
    "    for i in range(len(img_patches)):\n",
    "        patch = np.expand_dims(img_patches[i], axis = 0)\n",
    "        pred = road_model.predict(patch)\n",
    "        pred = pred[0][:, :, :]\n",
    "        pred_o = pred\n",
    "        pred_o = np.array(pred)\n",
    "        pred_o = pred_o[:, :, 0].reshape((512, 512))\n",
    "        \n",
    "        t_mask = pred_o\n",
    "        mean_mask = np.mean(t_mask)\n",
    "        np.place(pred_o[:, :], t_mask[:, :] < mean_mask*3, 0)\n",
    "        t_mask = pred_o\n",
    "        np.place(pred_o[:, :], t_mask[:, :] >= mean_mask*3, 1)\n",
    "        \n",
    "        predicted_images.append(pred_o)\n",
    "\n",
    "    vis_h_pred = []\n",
    "    vis_h_img = []\n",
    "    h_steps = int(img.shape[1]/patch_size[1])\n",
    "    v_steps = int(img.shape[0]/patch_size[1])\n",
    "    h_1 = 0\n",
    "    h_2 = h_steps\n",
    "    for _ in range(v_steps):\n",
    "        vis_h_pred.append(cv2.hconcat([predicted_images[i] for i in range(h_1, h_2)]))\n",
    "        vis_h_img.append(cv2.hconcat([img_patches[i] for i in range(h_1, h_2)]))\n",
    "        h_1 = h_2\n",
    "        h_2 += h_steps\n",
    "    predicted_image = cv2.vconcat([vis_h_pred[i] for i in range(len(vis_h_pred))])\n",
    "    img = cv2.vconcat([vis_h_img[i] for i in range(len(vis_h_img))])\n",
    "    \n",
    "\n",
    "    mask_on_img = placeMaskOnImg(img[0], np.repeat(np.expand_dims(predicted_image,-1), 3, 2),(66, 255, 73))\n",
    "    return 'Predicted Mask', predicted_image, 'Predicted Mask on Image', mask_on_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing UAV image to recognize humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_drone_image(image_source, patch_size=IMG_SIZE):\n",
    "    labels_to_names = {0: 'Human'}\n",
    "    \n",
    "    image = image_source\n",
    "    \n",
    "    draw = image.copy()\n",
    "    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "\n",
    "    boxes, scores, labels = human_model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    \n",
    "    boxes /= scale\n",
    "    humans = 0\n",
    "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "        if score < 0.5:\n",
    "            break\n",
    "        color = label_color(label)\n",
    "        humans+=1\n",
    "        \n",
    "        b = box.astype(int)\n",
    "        draw_box(draw, b, color=color)\n",
    "\n",
    "        caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "        draw_caption(draw, b, caption)\n",
    "        \n",
    "    draw_conv = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    img = (image_source/255.0)\n",
    "    img = np.expand_dims(cv2.resize(img, (512, 512)), 0)\n",
    "    img = img.astype(np.float32)\n",
    "    pred = road_model.predict(img)\n",
    "    pred = pred[0][:, :, :]\n",
    "    \n",
    "    mask = pred\n",
    "    t_mask = mask\n",
    "    np.place(mask[:, :, :], t_mask[:, :, :] < 0.0005, 0)\n",
    "    t_mask = mask\n",
    "    np.place(mask[:, :, :], t_mask[:, :, :] >=0.0005, 1)\n",
    "    pred = mask\n",
    "    \n",
    "    pred = np.repeat(pred, 3, 2) \n",
    "    mask_on_img = placeMaskOnImg(img[0], pred,(66, 255, 73))\n",
    "    return 'Predicted humans', draw_conv , f'{humans} humans were found on image', humans  #mask_on_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing staellite map image with recognized roads to find out, which is the shortest ways for recognized humans to get to the nearest localties by recognized roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_road_way_image(image_source, mask, coords, patch_size=IMG_SIZE):\n",
    "    img = (image_source/255.0).astype(np.float32)   \n",
    "    img = img[:, :, 0].reshape((512, 1024))\n",
    "    t_mask = img\n",
    "    np.place(img , t_mask < 50, 0)\n",
    "    t_mask = img\n",
    "    np.place(img , t_mask >= 50, 1)\n",
    "    base_h, base_w = img.shape[0]//2, img.shape[1]//2\n",
    "    matrix = img\n",
    "    start = (base_h, base_w)\n",
    "    closest_cell = find_closest(matrix, start)\n",
    "    matrix = img\n",
    "    results = []\n",
    "    for coord in coords:\n",
    "        t_h, t_w = get_pixels_by_coords(coord[0], coord[1],56.07461313, 34.43509312)\n",
    "        pix_h, pix_w = base_h+t_h, base_w+t_w\n",
    "        end = (pix_h, pix_w)  \n",
    "        start = (closest_cell) \n",
    "        result_matrix = find_three_shortest_paths(matrix, start, end, 2)\n",
    "        results.append(result_matrix)\n",
    "        \n",
    "    sat = img\n",
    "    img2 = mask\n",
    "    temp  = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    thickness = 5\n",
    "    for result_matrix in results:\n",
    "        for i in range(1,len(result_matrix[0][0])):\n",
    "            temp = cv2.line(temp, (result_matrix[0][0][i-1][1],result_matrix[0][0][i-1][0]), (result_matrix[0][0][i][1],result_matrix[0][0][i][0]), (255,0,0), thickness)\n",
    "        temp = cv2.line(temp, (base_w, base_h),(closest_cell[1],closest_cell[0]),(255,0,0),2)\n",
    "        temp = cv2.rectangle(temp, (base_w-5, base_h-5, 10, 10),(255,0,0),-1)\n",
    "     \n",
    "    patch_size=(800,800)\n",
    "\n",
    "    img_patches = []\n",
    "    for y in range(0, sat.shape[0], patch_size[1]):\n",
    "        for x in range(0, sat.shape[1], patch_size[0]):\n",
    "            img_patch = sat[y:y + patch_size[1], x:x + patch_size[0]]\n",
    "            img_patches.append(cv2.resize(img_patch, (512, 512)))     \n",
    "\n",
    "    vis_h_img = []\n",
    "    h_steps = int(sat.shape[1]/patch_size[1])\n",
    "    v_steps = int(sat.shape[0]/patch_size[0])\n",
    "    print(h_steps, v_steps)\n",
    "    h_1 = 0\n",
    "    h_2 = h_steps\n",
    "    for _ in range(v_steps):\n",
    "        vis_h_img.append(cv2.hconcat([img_patches[i] for i in range(h_1, h_2)]))\n",
    "        h_1 = h_2\n",
    "        h_2 += h_steps\n",
    "    edited_image = cv2.vconcat([vis_h_img[i] for i in range(len(vis_h_img))])\n",
    "    \n",
    "    color = [i/255.0 for i in (100, 20, 100)]\n",
    "    np.place(img2[:, :, :], temp[:, :, :] >= 100, color)\n",
    "    img2 = cv2.line(img2, (base_w, base_h),(closest_cell[1],closest_cell[0]),(255,0,0),2)\n",
    "    img2 = cv2.rectangle(img2, (base_w-5, base_h-5, 10, 10),(255,0,0),-1)\n",
    "    \n",
    "    #roadmap_on_sat = placeMaskOnImg(placeMaskOnImg(img[0], np.repeat(np.expand_dims(pred_o,-1), 3, 2), (0,255,0)),temp,(0,0,0))\n",
    "    print(edited_image.shape, img2.shape)\n",
    "    #color = [i/255.0 for i in (255, 255, 255)]\n",
    "    #print(img2.shape, temp.shape)\n",
    "    np.place(edited_image[:, :, :], np.repeat(np.expand_dims(img,-1), 3, 2)[:, :, :] >= 0.5, (100, 100, 0))\n",
    "    np.place(edited_image[:, :, :], temp[:, :, :] >= 100, (255, 255, 255))\n",
    "\n",
    "    \n",
    "    return 'Path on graph',img2 , 'Satellite roadmap and path', edited_image #roadmap_on_sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_app = gr.Blocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UI functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with my_app:\n",
    "    gr.Markdown(\"Aerial human segmentation\")\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"Find humans\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    drone_img_source = gr.Image(label=\"Please select source Image\")\n",
    "                    drone_source_image_loader = gr.Button(\"Find humans\")\n",
    "                    get_satellite_map = gr.Button(\"Get satellite map\")\n",
    "                with gr.Column():\n",
    "                    drone_output_label_mask = gr.Label(label=\"Image Info\")\n",
    "                    drone_mask_output = gr.Image(label=\"Image Mask\")\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    number_label = gr.Label(label=\"Number of humans\")\n",
    "        with gr.TabItem(\"Satellite map and roads\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    map_unlabelled = gr.Image(label=\"Please select source Image\")\n",
    "                    road_source_image_loader = gr.Button(\"Find roads\")\n",
    "                with gr.Column():\n",
    "                    road_output_label_mask = gr.Label(label=\"Image Info\")\n",
    "                    road_mask_output = gr.Image(label=\"Image Mask\")\n",
    "                with gr.Column():\n",
    "                    road_output_label_img = gr.Label(label=\"Image Info\")\n",
    "                    road_img_output = gr.Image(label=\"Mask on Image\")\n",
    "        with gr.TabItem(\"Find localties\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    road_way_img_source = gr.Image(label=\"Please select source Image\")\n",
    "                    road_way_source_image_loader = gr.Button(\"Find ways to localties\")\n",
    "                with gr.Column():\n",
    "                    road_way_output_label_mask = gr.Label(label=\"\")\n",
    "                    road_way_mask_output = gr.Image(label=\"\")\n",
    "                with gr.Column():\n",
    "                    road_way_output_label_img = gr.Label(label=\"\")\n",
    "                    road_way_img_output = gr.Image(label=\"\")   \n",
    "    get_satellite_map.click(\n",
    "        get_satellite_map_from_image,\n",
    "        [\n",
    "            drone_img_source,\n",
    "            number_label\n",
    "        ],\n",
    "        [\n",
    "            road_way_img_source,\n",
    "            map_unlabelled\n",
    "        ]\n",
    "    )         \n",
    "    drone_source_image_loader.click(\n",
    "        process_drone_image,\n",
    "        [\n",
    "            drone_img_source\n",
    "        ],\n",
    "        [\n",
    "            drone_output_label_mask,\n",
    "            drone_mask_output,\n",
    "            number_label\n",
    "        ]\n",
    "    )\n",
    "    road_source_image_loader.click(\n",
    "        process_road_image,\n",
    "        [\n",
    "            map_unlabelled\n",
    "        ],\n",
    "        [\n",
    "            road_output_label_mask,\n",
    "            road_mask_output,\n",
    "            road_output_label_img,\n",
    "            road_img_output\n",
    "        ]\n",
    "    )\n",
    "    road_way_source_image_loader.click(\n",
    "        process_road_way_image,\n",
    "        [\n",
    "            \n",
    "        ],\n",
    "        [\n",
    "            road_way_output_label_mask,\n",
    "            road_way_mask_output,\n",
    "            road_way_output_label_img,\n",
    "            road_way_img_output\n",
    "        ]\n",
    "    )\n",
    "    #map_unlabelled,\n",
    "    #road_output_label_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launching and closing app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "my_app.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 512)\n",
      "k_shortest_paths--------------0:00:00.851000\n",
      "k_shortest_paths--------------0:00:00.730000\n",
      "k_shortest_paths--------------0:00:00.315000\n",
      "2 1\n",
      "(512, 1024, 3) (512, 1024, 3)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Found 17 nearby cities and villages.\n",
      "{'name': 'Shchekoldino', 'address': 'Shchekoldino, Tver Oblast, Russia, 172317', 'lat': 56.0591328, 'lng': 34.4673425}\n",
      "{'name': 'Country house with farm in Shchekoldino', 'address': \"ул. Молодёжная, д. 25, Shchekoldino, Tverskaya oblast', Russia, 172317\", 'lat': 56.05581979999999, 'lng': 34.4490034}\n",
      "{'name': 'Territoriya Dzen', 'address': \"Тверская область, Зубцовский район, с/п Щеколдино, ул.Восточная, д.1, Зубцов, Tverskaya oblast', Russia, 172317\", 'lat': 56.0688681, 'lng': 34.4525223}\n",
      "{'name': 'Point of sales Tele2', 'address': \"улица Московская, 1A магазин Березка, Shchekoldino, Tverskaya oblast', Russia, 172317\", 'lat': 56.055826, 'lng': 34.4654542}\n",
      "{'name': 'Tomb Of Soviet Soldiers, Fallen In 1941-1943', 'address': 'Verigino, Tver Oblast, Russia, 172317', 'lat': 56.10287559999999, 'lng': 34.4486494}\n",
      "{'name': 'Гостевой Дом \"Василиса Прекрасная\"', 'address': 'Gnezdilovo, Tver Oblast, Russia, 172317', 'lat': 56.0912393, 'lng': 34.5154538}\n",
      "{'name': 'Khram Znameniya Bozhiyey Materi', 'address': 'Shchekoldino, Tver Oblast, Russia, 172317', 'lat': 56.0689527, 'lng': 34.4648704}\n",
      "{'name': \"Pomest'ye S Vodoyomom Okolo Reki\", 'address': \"Тверская обл., Зубцовский район, деревня Коротнево 30, Korotnevo, Tverskaya oblast', Russia, 172317\", 'lat': 56.0562208, 'lng': 34.44161520000001}\n",
      "{'name': \"Vazuzskaya Riv'yera\", 'address': \"ул.Береговая, д.38 дер, Shchekoldino, Tverskaya oblast', Russia, 172317\", 'lat': 56.0591881, 'lng': 34.4673932}\n",
      "{'name': 'Chasovnya Georgiya Pobedonostsa', 'address': 'Verigino, Tver Oblast, Russia, 172317', 'lat': 56.10301320000001, 'lng': 34.4484566}\n",
      "{'name': \"Chasovnya Bel'gardov\", 'address': 'Вазузское вдхр., обл., Tverskaya, Krasnodarskiy kray, Russia, 172317', 'lat': 56.0834437, 'lng': 34.5126275}\n",
      "{'name': 'Chasovnya', 'address': 'Vazuzskoye vdkhr., Тверская обл., Russia, 172317', 'lat': 56.0834331, 'lng': 34.5126909}\n",
      "{'name': 'Усадьба «Гнездило-ВО!»', 'address': \"Unnamed Road, Gnezdilovo, Tverskaya oblast', Russia, 172317\", 'lat': 56.0894154, 'lng': 34.5136547}\n",
      "{'name': 'Мемориал Великой Отечественной Войны', 'address': 'Zubtsovsky District, Tver Oblast, Russia, 172317', 'lat': 56.02766440000001, 'lng': 34.43492940000001}\n",
      "{'name': 'Kazan church', 'address': 'Tver Oblast, Russia, 172317', 'lat': 56.0352326, 'lng': 34.4891888}\n",
      "{'name': 'Named Grave Of Soviet Soldiers, Killed In 1942', 'address': 'Unnamed Road, Тверская обл., Russia, 172317', 'lat': 56.1174038, 'lng': 34.4806936}\n",
      "{'name': 'Verigino', 'address': 'Verigino, Tver Oblast, Russia, 172317', 'lat': 56.10146409999999, 'lng': 34.4516239}\n",
      "(225, 512)\n",
      "k_shortest_paths--------------0:00:00.327000\n",
      "k_shortest_paths--------------0:00:00.600000\n",
      "k_shortest_paths--------------0:00:00.611000\n",
      "2 1\n",
      "(512, 1024, 3) (512, 1024, 3)\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_app.launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
